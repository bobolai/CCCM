{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b843e250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Iprogress in /home/bobo/.local/lib/python3.8/site-packages (0.4)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from Iprogress) (1.14.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install Iprogress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f9b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from diffusers import AutoencoderKL, UNet2DConditionModel, DDPMScheduler\n",
    "from transformers import CLIPTokenizer, CLIPTextModel, CLIPImageProcessor\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lcm_pipeline import LatentConsistencyModelPipeline\n",
    "from lcm_scheduler import LCMScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd735dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import datetime\n",
    "import numpy as np\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f552b5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./lcm_images\"\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3dbb08e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3a605be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"SimianLuo/LCM_Dreamshaper_v7\"\n",
    "vae = AutoencoderKL.from_pretrained(model_id, subfolder=\"vae\")\n",
    "text_encoder = CLIPTextModel.from_pretrained(model_id, subfolder=\"text_encoder\")\n",
    "tokenizer = CLIPTokenizer.from_pretrained(model_id, subfolder=\"tokenizer\")\n",
    "unet = UNet2DConditionModel.from_pretrained(model_id, subfolder=\"unet\")\n",
    "scheduler = LCMScheduler(beta_start=0.00085, beta_end=0.0120, beta_schedule=\"scaled_linear\", prediction_type=\"epsilon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "663344b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = LatentConsistencyModelPipeline(vae=vae, text_encoder=text_encoder, tokenizer=tokenizer, unet=unet, scheduler=scheduler, safety_checker=None, feature_extractor=None)\n",
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "637ca0f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LCMScheduler {\n",
       "  \"_class_name\": \"LCMScheduler\",\n",
       "  \"_diffusers_version\": \"0.29.2\",\n",
       "  \"beta_end\": 0.012,\n",
       "  \"beta_schedule\": \"scaled_linear\",\n",
       "  \"beta_start\": 0.00085,\n",
       "  \"clip_sample\": true,\n",
       "  \"clip_sample_range\": 1.0,\n",
       "  \"dynamic_thresholding_ratio\": 0.995,\n",
       "  \"num_train_timesteps\": 1000,\n",
       "  \"prediction_type\": \"epsilon\",\n",
       "  \"rescale_betas_zero_snr\": false,\n",
       "  \"sample_max_value\": 1.0,\n",
       "  \"set_alpha_to_one\": true,\n",
       "  \"steps_offset\": 0,\n",
       "  \"thresholding\": false,\n",
       "  \"timestep_spacing\": \"leading\",\n",
       "  \"trained_betas\": null\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "949eeb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpm_scheduler = DDPMScheduler.from_pretrained(\n",
    "     \"runwayml/stable-diffusion-v1-5\", subfolder=\"scheduler\", revision=None\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddab4013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DDPMScheduler {\n",
       "  \"_class_name\": \"DDPMScheduler\",\n",
       "  \"_diffusers_version\": \"0.29.2\",\n",
       "  \"beta_end\": 0.012,\n",
       "  \"beta_schedule\": \"scaled_linear\",\n",
       "  \"beta_start\": 0.00085,\n",
       "  \"clip_sample\": false,\n",
       "  \"clip_sample_range\": 1.0,\n",
       "  \"dynamic_thresholding_ratio\": 0.995,\n",
       "  \"num_train_timesteps\": 1000,\n",
       "  \"prediction_type\": \"epsilon\",\n",
       "  \"rescale_betas_zero_snr\": false,\n",
       "  \"sample_max_value\": 1.0,\n",
       "  \"set_alpha_to_one\": false,\n",
       "  \"skip_prk_steps\": true,\n",
       "  \"steps_offset\": 1,\n",
       "  \"thresholding\": false,\n",
       "  \"timestep_spacing\": \"leading\",\n",
       "  \"trained_betas\": null,\n",
       "  \"variance_type\": \"fixed_small\"\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddpm_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "765d6304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct 16 14:17:59 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3090        Off | 00000000:01:00.0 Off |                  N/A |\r\n",
      "|  0%   55C    P2             111W / 350W |   6457MiB / 24576MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A      1067      G   /usr/lib/xorg/Xorg                          160MiB |\r\n",
      "|    0   N/A  N/A      1409      G   /usr/bin/gnome-shell                         43MiB |\r\n",
      "|    0   N/A  N/A      1982      G   ...AAAAAAAIAAAAAAAAAA== --shared-files       14MiB |\r\n",
      "|    0   N/A  N/A    477021      C   /home/bobo/LCMSenv/bin/python3             4986MiB |\r\n",
      "|    0   N/A  N/A    499610      C   /home/bobo/LCMSenv/bin/python3             1234MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc7fe5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae66dd313ce438ea479caa9c55296e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#prompt = \"potrait of adorable 11-year-old skinny small British girls in pool sexy bikini pose.(straight hair:1.2), (small breast:1.9), full body, skinny, smirk, smooth, sharp focus, highly detailed, photo realism\"\n",
    "prompt = \"smiling maitreya budai maltese dog, full body\"\n",
    "images = pipe(prompt=prompt, num_images_per_prompt=10, num_inference_steps=8, width=480, height=480, guidance_scale=6.0, lcm_origin_steps=50).images\n",
    "# cond + w*(cond - uncond)\n",
    "for i in range(len(images)):\n",
    "    image = images[i]\n",
    "    print(i)\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3cc445dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(images)):\n",
    "    if i==8 and i==5:\n",
    "        continue\n",
    "    current_time = datetime.datetime.now().strftime(\"%H-%M-%S-%f\")\n",
    "    filename = f\"{current_time}.png\"\n",
    "    output_path = os.path.join(save_path, filename)\n",
    "    image = images[i]\n",
    "    image.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "a4e96175",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 22 11:49:49 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3090        Off | 00000000:01:00.0 Off |                  N/A |\r\n",
      "|  0%   50C    P8              23W / 350W |  21618MiB / 24576MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A      1067      G   /usr/lib/xorg/Xorg                           24MiB |\r\n",
      "|    0   N/A  N/A      1409      G   /usr/bin/gnome-shell                          6MiB |\r\n",
      "|    0   N/A  N/A      1982      G   ...AAAAAAAIAAAAAAAAAA== --shared-files       13MiB |\r\n",
      "|    0   N/A  N/A      7918      C   /home/bobo/LCMSenv/bin/python3            21558MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "c68ed183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "a8238095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 19  39  59  79  99 119 139 159 179 199 219 239 259 279 299 319 339 359\n",
      " 379 399 419 439 459 479 499 519 539 559 579 599 619 639 659 679 699 719\n",
      " 739 759 779 799 819 839 859 879 899 919 939 959 979 999]\n"
     ]
    }
   ],
   "source": [
    "num_train_timesteps = 1000\n",
    "lcm_origin_steps = 50\n",
    "num_inference_steps = 4\n",
    "\n",
    "c = num_train_timesteps // lcm_origin_steps\n",
    "# LCM Training  Steps Schedule\n",
    "lcm_origin_timesteps = np.asarray(list(range(1, lcm_origin_steps + 1))) * c  - 1\n",
    "print(lcm_origin_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "dd81dc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "4\n",
      "12\n",
      "[999 759 519 279  39]\n"
     ]
    }
   ],
   "source": [
    "skipping_step = len(lcm_origin_timesteps) // num_inference_steps\n",
    "print(len(lcm_origin_timesteps))\n",
    "print(num_inference_steps)\n",
    "print(skipping_step)\n",
    "timesteps = lcm_origin_timesteps[::-skipping_step]\n",
    "print(timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "095e348e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99, 97, 95, 93, 91, 89, 87, 85, 83, 81, 79, 77, 75, 73, 71, 69, 67, 65, 63, 61, 59, 57, 55, 53, 51, 49, 47, 45, 43, 41, 39, 37, 35, 33, 31, 29, 27, 25, 23, 21, 19, 17, 15, 13, 11, 9, 7, 5, 3, 1]\n"
     ]
    }
   ],
   "source": [
    "tl = [i for i in np.arange(100)]\n",
    "print(tl[::-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "d4836d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0 , t= tensor(999)\n",
      "i= 1 , t= tensor(759)\n",
      "i= 2 , t= tensor(519)\n",
      "i= 3 , t= tensor(279)\n"
     ]
    }
   ],
   "source": [
    "for i,t in enumerate(scheduler.timesteps):\n",
    "    print(\"i=\",i,\", t=\",t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaf83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. LCM MultiStep Sampling Loop:\n",
    "with self.progress_bar(total=num_inference_steps) as progress_bar:\n",
    "    for i, t in enumerate(timesteps):\n",
    "\n",
    "        ts = torch.full((bs,), t, device=device, dtype=torch.long)\n",
    "\n",
    "        # model prediction (v-prediction, eps, x)\n",
    "        model_pred = self.unet(\n",
    "            latents,\n",
    "            ts,\n",
    "            timestep_cond=w_embedding,\n",
    "            encoder_hidden_states=prompt_embeds,\n",
    "            cross_attention_kwargs=cross_attention_kwargs, \n",
    "            return_dict=False)[0]\n",
    "\n",
    "        # compute the previous noisy sample x_t -> x_t-1\n",
    "        latents, denoised = self.scheduler.step(model_pred, i, t, latents, return_dict=False)\n",
    "\n",
    "        # # call the callback, if provided\n",
    "        # if i == len(timesteps) - 1:\n",
    "        progress_bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e3318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Sample z ~ N(0, I), For MultiStep Inference\n",
    "# Noise is not used for one-step sampling.\n",
    "\n",
    "if len(timesteps) > 1:\n",
    "    noise = torch.randn(model_output.shape).to(model_output.device)\n",
    "    prev_sample = alpha_prod_t_prev.sqrt() * denoised + beta_prod_t_prev.sqrt() * noise\n",
    "else:\n",
    "    prev_sample = denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "7fbe29c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalings_for_boundary_conditions(timestep, sigma_data=0.5, timestep_scaling=10.0):\n",
    "    scaled_timestep = timestep_scaling * timestep\n",
    "    c_skip = sigma_data**2 / (scaled_timestep**2 + sigma_data**2)\n",
    "    c_out = scaled_timestep / (scaled_timestep**2 + sigma_data**2) ** 0.5\n",
    "    return c_skip, c_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "8e4551c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 0.0)\n",
      "(0.0024937655860349127, 0.9987523388778445)\n",
      "(2.5050075037374525e-09, 0.9999999987474963)\n"
     ]
    }
   ],
   "source": [
    "print(scalings_for_boundary_conditions(0))\n",
    "print(scalings_for_boundary_conditions(1))\n",
    "print(scalings_for_boundary_conditions(999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6367a89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.configuration_utils import ConfigMixin, register_to_config\n",
    "from diffusers.schedulers import SchedulerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "654375a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchedulerTest(SchedulerMixin, ConfigMixin):\n",
    "    @register_to_config\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_train_timesteps: int = 1000,\n",
    "        beta_start: float = 0.00085,\n",
    "        beta_end: float = 0.012,\n",
    "        beta_schedule: str = \"scaled_linear\",\n",
    "        trained_betas= None,\n",
    "        original_inference_steps: int = 50,\n",
    "        clip_sample: bool = False,\n",
    "        clip_sample_range: float = 1.0,\n",
    "        set_alpha_to_one: bool = True,\n",
    "        steps_offset: int = 0,\n",
    "        prediction_type: str = \"epsilon\",\n",
    "        thresholding: bool = False,\n",
    "        dynamic_thresholding_ratio: float = 0.995,\n",
    "        sample_max_value: float = 1.0,\n",
    "        timestep_spacing: str = \"leading\",\n",
    "        timestep_scaling: float = 10.0,\n",
    "        rescale_betas_zero_snr: bool = False,\n",
    "    ):\n",
    "        if trained_betas is not None:\n",
    "            self.betas = torch.tensor(trained_betas, dtype=torch.float32)\n",
    "        elif beta_schedule == \"linear\":\n",
    "            self.betas = torch.linspace(beta_start, beta_end, num_train_timesteps, dtype=torch.float32)\n",
    "        elif beta_schedule == \"scaled_linear\":\n",
    "            # this schedule is very specific to the latent diffusion model.\n",
    "            self.betas = torch.linspace(beta_start**0.5, beta_end**0.5, num_train_timesteps, dtype=torch.float32) ** 2\n",
    "        elif beta_schedule == \"squaredcos_cap_v2\":\n",
    "            # Glide cosine schedule\n",
    "            self.betas = betas_for_alpha_bar(num_train_timesteps)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"{beta_schedule} is not implemented for {self.__class__}\")\n",
    "\n",
    "        # Rescale for zero SNR\n",
    "        if rescale_betas_zero_snr:\n",
    "            self.betas = rescale_zero_terminal_snr(self.betas)\n",
    "\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
    "\n",
    "        # At every step in ddim, we are looking into the previous alphas_cumprod\n",
    "        # For the final step, there is no previous alphas_cumprod because we are already at 0\n",
    "        # `set_alpha_to_one` decides whether we set this parameter simply to one or\n",
    "        # whether we use the final alpha of the \"non-previous\" one.\n",
    "        self.final_alpha_cumprod = torch.tensor(1.0) if set_alpha_to_one else self.alphas_cumprod[0]\n",
    "\n",
    "        # standard deviation of the initial noise distribution\n",
    "        self.init_noise_sigma = 1.0\n",
    "\n",
    "        # setable values\n",
    "        self.num_inference_steps = None\n",
    "        self.timesteps = torch.from_numpy(np.arange(0, num_train_timesteps)[::-1].copy().astype(np.int64))\n",
    "        self.custom_timesteps = False\n",
    "\n",
    "        self._step_index = None\n",
    "        self._begin_index = None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d2adb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_test = SchedulerTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fdea956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SchedulerTest {\n",
       "  \"_class_name\": \"SchedulerTest\",\n",
       "  \"_diffusers_version\": \"0.29.2\",\n",
       "  \"beta_end\": 0.012,\n",
       "  \"beta_schedule\": \"scaled_linear\",\n",
       "  \"beta_start\": 0.00085,\n",
       "  \"clip_sample\": false,\n",
       "  \"clip_sample_range\": 1.0,\n",
       "  \"dynamic_thresholding_ratio\": 0.995,\n",
       "  \"num_train_timesteps\": 1000,\n",
       "  \"original_inference_steps\": 50,\n",
       "  \"prediction_type\": \"epsilon\",\n",
       "  \"rescale_betas_zero_snr\": false,\n",
       "  \"sample_max_value\": 1.0,\n",
       "  \"set_alpha_to_one\": true,\n",
       "  \"steps_offset\": 0,\n",
       "  \"thresholding\": false,\n",
       "  \"timestep_scaling\": 10.0,\n",
       "  \"timestep_spacing\": \"leading\",\n",
       "  \"trained_betas\": null\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1781e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "a3ada102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f18cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_root = '/home/bobo/LCMSenv/data/mnist_5x10_64'\n",
    "data_root = '/nfs/work/dataset/mnist_5x10_64'\n",
    "os.makedirs(data_root, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "61b8cb84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiip7S0nvrlLe3jZ5HOAAM19IfD34L6fp+nQ3/iCFZrpvmaBxlQO1ZvxZ+GWjQ+HrjW9DiCTROoNvAvy4PXpXz2ysjFWUqR1BGKSiip7OzuL+6jtrWJpZpDtVFGSTX1P8PPhto/hfSLXV7+32aiI90jSHhPXiuksfH2ganPd24uo0ggX5pi3yn2FcX4C8XadeeNdW0G3cTwXMryRljuBAHavE/ijYHT/HV7EIDEpwQMYrjaKAMnAr6B+EXgix0zQh4v1clBFlwGH3QO9ZHjb43T6q13pmnxKtmxKrMOGIrx5b+6jjkijndY3J3KDwc13/AMC/+So2X/XGT+Vdj+0TY28cljeLGBPI5VmxyQBXg1Favhy0ivdetIJhlGcZH419GfGPWF8OeALTT7ZNiXS+VheOMV8vUV7F8CPC+ot4qj8QPGY7KCN1LMOuRUHxw8Y22vaymm2oylo2fMB4JxXklFbnhD/kZ7L/AHx/OvdPjp4b1HVdG028sg8yRAF4uyjb1FeGaT4P1zWrjyLOxkL5x8wIFeq+D/gibYC/8WyC2jTkRggg/WqnxH+I39nwjw54WK2lnGMPNCcFsV43LLJPI0krl3Y5LHqaZRVvTL59N1GG7j6xsDX1T4T+LXhrXtMVNRuYLOREAZbhhhqXX/il4Q8M2plsJLa9kbnbbEZBrwjxh8Vtc8T3E8aTGGxkGFiA5A+tcEzFjliSfUmkooooooooor//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAAFB0lEQVR4Ae2VbVMaVxTH791dYHcRhF2CAhIIKD4STUxNbJppps10On3XV/1W/RD9Ap3MdDqTyTQzTZO2MYlREzWIKIiAyLPALg/L3l6sxH1ATF835wXLvXvO75z7v/fcBeCTfVIAAHi5CNBAswwDRFFoSLLOndLN6CYM9kBoMghikch+uYW0ry8FQJMrEL5xcw6889jYWLr93wHOL+/5R8cA8JGe649/0QG0QO3Y4HjwU1FqSdjaUvFHl/Y9uGQJRu+N5Xk7IEEbGACwO21ZrYyDARQX/v7OCIKoLXWaJANY19FJR13EIAA0jc3eXQgABFBHqBTkccfYPUviqCIqEYMAxiuffbfgBgBBKJ3svRQe3J+03nqx+jb5UQDSbOf9y8t+4uywiQe5iZrV6pSqBx8HYObnJwL+ERJngwCZeA9/Us94WCN3hVUWcPEuDC98M+eDqNM9ehAYjY5hQzFGXZUZi/GjABQfmHRDAKFQyQjeAIaIuY6BcRuhrN6GC0Sk7Fd9owYEQSObWC8vew0gd5w6ao3cZCCeVFp/gAmfn/EhCCQh/iqaJjwRObMeOZbb15tDdjfPNhSnqS+Asi/+sOjAmYTkys9Rzpd8ll2NHVVRPdOE7slrjqyiKfsAIMUFwzevAhm287HNt0m3sXOQXivguts1CdCjwZCUPdehD4CwjC/NWACQUS21GRNAKZIghcrpurvLZ6byzcIgAGXzXV8M0nK51C5uvU+18VX0QTQCEwzemR18unqmr4Ceun0rPMbW3mwUStlMWep59p7EkJ3tVnJmeoBl7v6MmwbJv54cVpGpeV7sWQQ0mKgBAKxgYNpFV7Zf/P2+0CJYpAMA2F3IB9NWQFndvjEj2H/4PIqVQgLuZa0hWTmnBbChBb8JCAdrmyXshpSuXVA3t7oChZ6nmWyff+UDjXQCr/90rP6BGAAJQhmkroCgXOEwL1eTyWLf6/cUKjWVO6MGmJ0hL0/JhXi6pU59NmphSaFQriuqUwPoUS9Pg052N61M0mNBSOO7Rcwkihc2E2miTQDUU9vxRi9K8RzxTjJY31dP9xR4dQXYG8tUz0TxCdYZPX53nkX5yJ9PqxcDYFfnTi2vl4DgfLfvTTGV6EaspGRrKvhXnXafBTBTS1/f5lBqdTWnjNdfqhA1chVtASRtvnbnzuRQPrb+eqc8EAApOfk2pVD51Nvsm124GzTGnz9KpEvn3d19p1kCvoZRvax2ISnOO7c0P83GXz5+qFucGoAllImRoK2prJILzM2HfFwr8ftv27p4XQWoQ7imvWz9nECPL3+x5IK16Mtfnyi2r+egrgD3nwygfeLWYaEuEbTFxlvo4dnZEE/UU1vrca22XYgagLDha3P6242tjEjxYxMzHo5zDoNqJhddeVfuZVU+1QB42usG75KVzwik0xcYd3FDEBWP4ju7W/EqVDRRD6IBkAT+HEMH6w5XBMLhtLJmExDzmcTrZ6mqoPic9MK1S5AEQeyQpNnM+xoNaKOxX7uyv59Nrb4RzmNU/9QV1I9Sx34LbgeCNjAQNyZopN7/sV6vHV8UrxFRPE7sOj1WEm8FSYCOLInpyKtHa6qUmoG6AlmMP8mHgn4Oe0FwcnCYPEjsxTUh6qEaAKTDk+jcotwFAJBYWdtIlsQ+V4OCoQGgZk5s18t7NAKwubu1s5dX+Pb9iwXTGEkzQ2z34pZFQWgMTq8J/TT8/yrwD/w09mimO+kwAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms.ToPILImage()(mnist.data[1]).resize((64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1129c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "mnist = datasets.MNIST(root='./data', train=True, download=True, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "736ad999",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of label 0 is 5923\n",
      "len of label 1 is 6742\n",
      "len of label 2 is 5958\n",
      "len of label 3 is 6131\n",
      "len of label 4 is 5842\n",
      "len of label 5 is 5421\n",
      "len of label 6 is 5918\n",
      "len of label 7 is 6265\n",
      "len of label 8 is 5851\n",
      "len of label 9 is 5949\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "classes_sortby_idx = {0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[],9:[]}\n",
    "\n",
    "for i in range(len(mnist)):\n",
    "    classes_sortby_idx[int(mnist.targets[i])].append(i)\n",
    "    \n",
    "for cls in range(len(mnist.classes)):\n",
    "    print(f\"len of label {cls} is {len(classes_sortby_idx[cls])}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5f6ac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_PIL = transforms.ToPILImage()\n",
    "zeros_channel = torch.zeros_like(mnist.data)\n",
    "\n",
    "mnist_imgs = dict()\n",
    "mnist_imgs['bw'] = mnist.data.unsqueeze(1).repeat(1,3,1,1)\n",
    "mnist_imgs['red'] = torch.stack((mnist.data, zeros_channel, zeros_channel), dim=1)\n",
    "mnist_imgs['grn'] = torch.stack((zeros_channel, mnist.data, zeros_channel), dim=1)\n",
    "mnist_imgs['blu'] = torch.stack((zeros_channel, zeros_channel, mnist.data), dim=1)\n",
    "mnist_imgs['ylw'] = torch.stack((mnist.data, mnist.data, zeros_channel), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "787afdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in range(len(classes_sortby_idx)):\n",
    "    # Directory paths for each image\n",
    "    for k in mnist_imgs:\n",
    "        os.makedirs(os.path.join(data_root, f'{k}_{cls}'), exist_ok=True)\n",
    "                 \n",
    "    for idx in classes_sortby_idx[cls]:\n",
    "        colored_img = []\n",
    "        for k in mnist_imgs:\n",
    "            # 1 image for each bw, red, green, blue, yellow \n",
    "            colored_img.append(to_PIL(mnist_imgs[k][idx]).resize((64, 64)))\n",
    "\n",
    "            for img in colored_img:\n",
    "                img.save(os.path.join(data_root, f'{k}_{cls}', \"{:05d}.jpg\".format(idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5d5e813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/ooooAKKKmtbWa8uEggQvI5wABSbSV2BDRX0N4E+EdjY2EV7rkKzXLfM0LjKgdqz/if8O9Jh0KfWNGjCSxOAYIV45614EOI8JPFfV433tfpc19jLlueE0UrKyMVZSCOxFJX0BkFFFAGTigCa0tJ725jt7aNpJXOFVRyTX0p4E+H2leHNKt9VvoNt/wCXucyHhfwrl/hb4OstO0YeKdUJTy8uAw+6B3rL8YfGKbUmutOsYlW0JIWUdSK+RzOticzrPCYTSMfif6HRBKC5pHrln430PUZrqAXKJDCvzSlvlPsK5HwT4psLvxfqmiwOJobiRnQsdwIA7V89re3MaPGkzrG5O5QeDXcfBn/ko9n/ANcpP5VnX4do4TC1pqTfu6eq1uCquUkjM+JFkbHxpeRiExLwQMYrkq9r+PVlBHJZ3aoBNI+1mxyRivFK9/J8R9YwVOflb7jKorSaCtLQLWO81u1hlGUZxkfjWbWz4V/5GOz/AN8fzrurtqlJrsyVue6/FjVV0DwRa2Num1blfLwvHavnGvoD4z+H7/U9J0+6tA8qR8vH2UbeorxjTPCus6vP5NpZuX6fMMV8/wAOToUsBzuSu22zWtdyMavV/gt4cvz4lTXHjKWcCMCzDrkVe8K/B024F94okFuiciMEEH61V8f+PvsMQ0Dw2VtbVBh5YTgnFVjMf9f5sFg9b6OXRL9QjHk96RV+Mfiu31vVk0+2GUtmzvB4JxXl1PkleaQySMWc8knvTK9nBYSGEoRow2RnKXM7hVrTr19Pv4bpOsbA1VorplFSVmSfUHhj4oeHtb05Vv7iG0kRACs5GGpdb+JPhXw7bGSye3u5G5225GQa+XqK+YfCmE9rzcz5exv7eVjt/FXxM1nxFPMizGGzcYEeOQPrXElixyxJPqaSivocPhqWHhyUo2Ri5N6sKKKK3Ef/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAIUklEQVR4Ae3Z6Y5VVRAF4AIRFBUnRhUccAIVRRREMBA0xvCPX7wVD8ELGBJCQogkKDgg4MAg4gAoMjkig4igfttqj50Guvc53CZGb2Xn5vSZdq2qVWvXPh3Rt34E+hHoR6Afgf9zBMZcH/BjxsSNN8ZNN8XEiXHzzWWwX34p49y5OH8+Ll6M33/v4su4Lg+1f4b3d94ZDz0Ujz4ajz0Ws2eXV3zxRXz6aRkHD8ZPP8WFC/HHH61fPeoAxH7ChJgxo3j/1FMxf348+2w8+WRxdM+euPfeuOOOkhZgjh6N3377VwKYOjWWLYuXXooHHojp0+O++wa8vP/+uOGGgmHevNi0Kdav7wKgNeJWD2DO5Mnxyiuxdm388EMhOp74bYaQO3ZpzZqSpQ42ihQaPz5mziycWbw4nn661AATcpZUAS/NJVnCpRMnWpfyaAEYNy7uuquQftWqeOGFmDatFKh68JtRv3Qpfv214ElFUgYycPx4/PxzuFRvvQeQVYvoTzwRS5bEM8+U8mWpMH75RzpPnYrvvy/xfvjhQjP3K5LbbovDhwsMVylsjfUeAOZMmRLPPx8rVxbv77lnwI3MAHhIL8xffhnvv1+QqJDly4u2TpoUzz0X770Xu3bF7t3x9dc1/kfPACDDLbcUot99d1EbvDccjB074AfXB5sAf/VVfPttPPJInDlTvDdUAninT5dL1xsAKqtUg0M4w3W8z5JNvxOAPFgWgKSefqXi7Nk4dqz8qQxkT+VIoONK61kGbr+9EObVV8siReC5m3T321hi4KWB9x4hRDTUKqboZ80qJSEQKsENldYbAKYXToFHZaRPR/0aWa9i7ICqZkFzziUsQiE1DQa/Pchv58GoF6IeAOA96oufwFtoeZP1yktdGmknLB99VLodVQFDyj/XT56Mb74pmmN1wzctBhgANI/XJOFaASB0s1oRxFtvLR4wtSjkhw7Fjh3x2Welz1HNiK51E2AJAckxDP60MugmLAseFwupkE9lAL+rw9s1AcjYL1gQq1eHX7RO703JezKyfXu8/noBoDTlx5mtW0tOCCXeiz3BEe+sYwA8zns8fPDB8jZ3jtiidgRgJt5zS2NsuZV9FGIC5pKIfvddcXHv3gFFT35jNn2UjQ8/LKtYY+6npJLG7Bnw0Gs13s7AMHw9dASAD7QCZxYujLlzy3EaACLKG+TmPQxSwX78sRBGMRBWZyy0Q6xJnfMq4fHHSwjkBM7eAxB7jRdKIC7miJawcV2ZclQ4KeO+fbF/f4HhT0Zwhm8NRKTBoMrVlbgcOPDPOjgEcPNnlwxwV4QWLSorP/5oYxScqH/wQXz8cYkZGFKvUkFKYjTz1RwAk9XstQ2qqz3YBQDCWK00MIKE3PAwBfrOO7F5cxw5MlCaBAoHhifAFd3itCR4XKp7DMDrsnatR3PmlAaY9wj9ySelCXv33UIbGSAdoih+6qEDAKhMNJhUV8SZJ9tlgPdaLlFXAJiTC74t+bp1sW1bkcum5rie5eugg3kq9WDEZ9sBEFTqpufRq0kx4yVlJIs0B/Ubdx00xyM6kTcMZkt9Bv5udusmIT4vvhgrVpQMMCslUSeODe/rXnOFu3jcAEjvUcgY0Woz4F34g/Rkx7DUS7F1VO0adDPlcsT5rnbDkHTRLgJQo2C1AGxW7Dbwh0LzHhgAMF63Iwmq9hrNG5pylwHMJMFajCHALp+lFgC1scKn96mb5iP2n39eANSE6vK580ySxzuTQjy25FlDMFNihWl4qwWgBVC1psna9VLhsdASUElQDJ1NIy0uGjgdBEtV0MO++WbZN48YmloAjX8ZJ39mC0k6m36huaf+QEQ0VD5e2IvmuqEF0jW9/XYBoMZ6CSBz3QBAIe2D+boVAFXIHltL4oOK3kQGrIkioh/RBRLlGmuRgcvrifJ0Jk+2nJrZl18ubRUw3i+ZtgqG/VqltQCQb5QBM/HbHALWNvxqCW1omi2LL3YG9mvdcv9gm7ZzZ2lCSVCltQPA+xRQ2u/bk4CNqBJD/OC6RdBHO8s56mvF9SNkQCeycWNRHpqGPMP33oPf2RpAZkAFC1L9NAIPOZ4QHJ0s5qha7aDC5b1PdD6va6g6ELIWAL8NJuTqj/YJns7CelljXNfAcp3fVkNJcAb9hHzLlnjjjSLHHbw3dS2A9BL7iQ8AegrxE04hlI3hLbXSN5WlS0vsPSsWFIzgiP2GDWUXMaJcXm2K1gCS9Dzw/cNXRJsynZyeAgxOwMZdOx7J0XE48KcvcEhviL2T7nGz+rHtVLUo1FYJBoOpBSD2zcjn6aAkvPZakW2uWPyVBKJz0VYBNvs1H4JQxdBHgcGsTe6kYMLvo4t/k9ULzmC/m+NaAFkDgpeV4PnceqOELQ6nuaULUKx8RXGMt8RiC+/zaxf8ehvfgoScUGqiwHYMkne62s1aAOAcAH7TzOrbkxqwQdNgWxMAcIOTMEDlEtHM3klyKH22aJTe5y0U4rpH8Kez9zypBYDfJjO4oo7BMPhnCL+Q0xADKuzH+8as1rDZdhq611xrfb/wqp5YLQBlJ/um9zXTflJ1NlwSdR5jlKpwsmlX+QeSR+z033qr1KuXEB9v6JX3pqgFIPAmJtu4iyGqE0kkoRElx5Aw+XFSxjxiWdVa6o2tsvbNo2G1APjEITVHs7GZIFrIpEKNNpY58U8X23zaqt1wALO23oOjZLUATC+o3OIfBbSm+qgI1WAA6SKP6aN4k1cYsrG5xh3zMOBbAKAVGgcSLhUcQmgSLroKIGVEBtyQ+kgoXZKr0ba/+puWk6A7p5UsgaeVSf18RzIt9UoFj17gW7rcv70fgX4E+hHoR+C/GoE/ARnw7CqJqqvEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_PIL(mnist_imgs['ylw'][1]).resize((64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c811cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.py --arch unetic --data /root/notebooks/nfs/work/dataset/mnist_5x10_64 --lr 6e-5 --num_condition 5 10 --epochs 50 --exp Colored_Mnist_5x10 --dir ddim_IC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LCMStest1",
   "language": "python",
   "name": "lcmstest1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
